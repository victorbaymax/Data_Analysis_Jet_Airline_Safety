{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e472eed0",
   "metadata": {},
   "source": [
    "# Aviation Accidents Cleaning\n",
    "\n",
    "This notebook loads the combined aviation accidents dataset and performs client-driven filtering and cleaning. It produces a cleaned CSV that will be used in the downstream analysis notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e036ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"Combined_Aviation_With_States.csv\"  # file is in the same directory as this notebook\n",
    "df_raw = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258331b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect dataframe structure\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b16d5",
   "metadata": {},
   "source": [
    "## Inspect NaNs and datatypes\n",
    "\n",
    "We inspect missingness (NaNs) and datatypes to understand what needs cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values (top 25)\n",
    "na_counts = df_raw.isna().sum().sort_values(ascending=False)\n",
    "na_pct = (na_counts / len(df_raw)).round(4)\n",
    "missing_summary = pd.DataFrame({\"na_count\": na_counts, \"na_pct\": na_pct})\n",
    "missing_summary.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe809a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatypes\n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d2e412",
   "metadata": {},
   "source": [
    "## Summary statistics\n",
    "\n",
    "Numeric columns are summarized with `describe()`. For categorical columns, we use `describe(include='object')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335cf055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.describe(include=[np.number]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.describe(include=[\"object\"]).T.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4bbbb",
   "metadata": {},
   "source": [
    "## Filtering aircraft and events\n",
    "\n",
    "Client constraints:\n",
    "\n",
    "- **Aircraft.Category**: only **Airplanes**\n",
    "- **Amateur.Built**: only **professional builds** (i.e., Amateur.Built == 'No')\n",
    "- **Event.Date**: remove events older than **40 years** (relative to **2026-02-14** for reproducibility)\n",
    "\n",
    "### Assumptions\n",
    "- If `Aircraft.Category` is missing or not 'Airplane', we exclude it (client only wants airplanes).\n",
    "- If `Amateur.Built` is missing, we treat it as **Unknown** and exclude it (client only wants professional builds).\n",
    "- If `Event.Date` cannot be parsed, we exclude it (cannot verify age constraint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str_series(s: pd.Series) -> pd.Series:\n",
    "    return (s.astype(\"string\")\n",
    "              .str.strip()\n",
    "              .str.replace(r\"\\s+\", \" \", regex=True))\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Parse dates\n",
    "df[\"Event.Date\"] = pd.to_datetime(df[\"Event.Date\"], errors=\"coerce\")\n",
    "\n",
    "# Standardize relevant filter columns\n",
    "df[\"Aircraft.Category\"] = clean_str_series(df[\"Aircraft.Category\"]).str.title()\n",
    "df[\"Amateur.Built\"] = clean_str_series(df[\"Amateur.Built\"]).str.title().replace({\"Nan\": pd.NA, \"\": pd.NA}).fillna(\"Unknown\")\n",
    "\n",
    "# Client filters\n",
    "cutoff = pd.Timestamp(\"2026-02-14\") - pd.DateOffset(years=40)  # 1986-02-14\n",
    "df = df[df[\"Aircraft.Category\"].eq(\"Airplane\")]\n",
    "df = df[df[\"Amateur.Built\"].eq(\"No\")]\n",
    "df = df[df[\"Event.Date\"].ge(cutoff)]\n",
    "\n",
    "print(\"After client filters shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab26850",
   "metadata": {},
   "source": [
    "## Injuries and robustness to destruction\n",
    "\n",
    "Client cares about:\n",
    "\n",
    "1. **Likelihood of serious/fatal injury**\n",
    "2. **Whether an aircraft was destroyed**\n",
    "\n",
    "### Cleaning assumptions\n",
    "- Injury columns are coerced to numeric (`errors='coerce'`).\n",
    "- We estimate **Passengers.Est** as the sum of:\n",
    "  - `Total.Fatal.Injuries` + `Total.Serious.Injuries` + `Total.Minor.Injuries` + `Total.Uninjured`\n",
    "- If **all** four injury fields are missing for a row, passengers and rates are set to **NaN** (unknown).\n",
    "\n",
    "### Derived columns\n",
    "- `Passengers.Est`\n",
    "- `Serious.Fatal.Injuries`\n",
    "- `Fatality.Rate` = Fatal / Passengers.Est\n",
    "- `SeriousOrFatal.Rate` = (Serious + Fatal) / Passengers.Est\n",
    "- `Was.Destroyed` (boolean) derived from `Aircraft.damage == 'Destroyed'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ce232",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_cols = [\"Total.Fatal.Injuries\",\"Total.Serious.Injuries\",\"Total.Minor.Injuries\",\"Total.Uninjured\"]\n",
    "\n",
    "for c in inj_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "all_null = df[inj_cols].isna().all(axis=1)\n",
    "\n",
    "df[\"Passengers.Est\"] = df[inj_cols].fillna(0).sum(axis=1).where(~all_null, np.nan)\n",
    "df[\"Serious.Fatal.Injuries\"] = (df[\"Total.Fatal.Injuries\"].fillna(0) + df[\"Total.Serious.Injuries\"].fillna(0)).where(~all_null, np.nan)\n",
    "\n",
    "df[\"Fatality.Rate\"] = np.where(df[\"Passengers.Est\"]>0, df[\"Total.Fatal.Injuries\"].fillna(0)/df[\"Passengers.Est\"], np.nan)\n",
    "df[\"SeriousOrFatal.Rate\"] = np.where(df[\"Passengers.Est\"]>0, df[\"Serious.Fatal.Injuries\"]/df[\"Passengers.Est\"], np.nan)\n",
    "\n",
    "# Aircraft damage -> destroyed flag\n",
    "df[\"Aircraft.damage\"] = clean_str_series(df[\"Aircraft.damage\"]).str.title().fillna(\"Unknown\")\n",
    "df[\"Was.Destroyed\"] = df[\"Aircraft.damage\"].eq(\"Destroyed\")\n",
    "\n",
    "df[[\"Total.Fatal.Injuries\",\"Total.Serious.Injuries\",\"Total.Minor.Injuries\",\"Total.Uninjured\",\n",
    "    \"Passengers.Est\",\"Serious.Fatal.Injuries\",\"Fatality.Rate\",\"SeriousOrFatal.Rate\",\n",
    "    \"Aircraft.damage\",\"Was.Destroyed\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0172c",
   "metadata": {},
   "source": [
    "## Investigate the Make column\n",
    "\n",
    "### Cleaning tasks\n",
    "- Trim whitespace and normalize repeated whitespace\n",
    "- Uppercase for consistent grouping (e.g., `Cessna` vs `CESSNA`)\n",
    "- Remove most punctuation (keeps word characters, spaces, `&`, `/`, `-`)\n",
    "- Fill missing makes with `UNKNOWN`\n",
    "\n",
    "### Filtering threshold\n",
    "For analysis, keep only makes with **>= 50 records**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f52f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Make\n",
    "df[\"Make\"] = clean_str_series(df[\"Make\"]).str.upper().replace({\"<NA>\": pd.NA, \"\": pd.NA}).fillna(\"UNKNOWN\")\n",
    "df[\"Make\"] = df[\"Make\"].str.replace(r\"[^\\w\\s&/-]\", \"\", regex=True).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "make_counts = df[\"Make\"].value_counts()\n",
    "make_counts.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply make threshold (>=50)\n",
    "valid_makes = make_counts[make_counts >= 50].index\n",
    "df = df[df[\"Make\"].isin(valid_makes)].copy()\n",
    "\n",
    "print(\"After make>=50 shape:\", df.shape)\n",
    "print(\"Unique makes:\", df[\"Make\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3096c7",
   "metadata": {},
   "source": [
    "## Inspect Model column\n",
    "\n",
    "### Tasks\n",
    "- Fill missing models with `UNKNOWN_MODEL`\n",
    "- Normalize whitespace and uppercase\n",
    "- Check whether model labels are unique across makes\n",
    "- Create derived identifier `Plane.Type = Make + ' ' + Model` to uniquely represent plane type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Model\n",
    "df[\"Model\"] = clean_str_series(df[\"Model\"]).str.upper().replace({\"<NA>\": pd.NA, \"\": pd.NA}).fillna(\"UNKNOWN_MODEL\")\n",
    "df[\"Model\"] = df[\"Model\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Check models that appear across multiple makes\n",
    "model_make_n = df.groupby(\"Model\")[\"Make\"].nunique().sort_values(ascending=False)\n",
    "multi_make_models = model_make_n[model_make_n > 1]\n",
    "print(\"Models appearing under multiple makes:\", len(multi_make_models))\n",
    "multi_make_models.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived unique plane type id\n",
    "df[\"Plane.Type\"] = df[\"Make\"] + \" \" + df[\"Model\"]\n",
    "df[[\"Make\",\"Model\",\"Plane.Type\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe502570",
   "metadata": {},
   "source": [
    "## Cleaning other columns\n",
    "\n",
    "Columns potentially related to accident outcomes:\n",
    "\n",
    "- `Engine.Type`\n",
    "- `Weather.Condition`\n",
    "- `Number.of.Engines`\n",
    "- `Purpose.of.flight`\n",
    "- `Broad.phase.of.flight`\n",
    "\n",
    "### Cleaning approach\n",
    "- Strip whitespace and normalize casing\n",
    "- Fill missing categorical values with `Unknown`\n",
    "- Coerce `Number.of.Engines` to numeric (`Int64`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engine.Type\n",
    "df[\"Engine.Type\"] = clean_str_series(df[\"Engine.Type\"]).str.title().fillna(\"Unknown\")\n",
    "\n",
    "# Weather.Condition (normalize common codes)\n",
    "df[\"Weather.Condition\"] = clean_str_series(df[\"Weather.Condition\"]).str.upper().fillna(\"UNKNOWN\")\n",
    "df[\"Weather.Condition\"] = df[\"Weather.Condition\"].replace({\"UNK\":\"UNKNOWN\",\"UNKN\":\"UNKNOWN\"})\n",
    "\n",
    "# Number.of.Engines\n",
    "df[\"Number.of.Engines\"] = pd.to_numeric(df[\"Number.of.Engines\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Purpose / phase\n",
    "df[\"Purpose.of.flight\"] = clean_str_series(df[\"Purpose.of.flight\"]).str.title().fillna(\"Unknown\")\n",
    "df[\"Broad.phase.of.flight\"] = clean_str_series(df[\"Broad.phase.of.flight\"]).str.title().fillna(\"Unknown\")\n",
    "\n",
    "df[[\"Engine.Type\",\"Weather.Condition\",\"Number.of.Engines\",\"Purpose.of.flight\",\"Broad.phase.of.flight\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e393da2",
   "metadata": {},
   "source": [
    "## Column removal\n",
    "\n",
    "Drop columns with too many missing values.\n",
    "\n",
    "**Rule:** keep columns with **more than 20,000 non-null values** (evaluated at this stage after client filtering, before downstream analysis).\n",
    "\n",
    "> Note: At this stage, we still have more than 20,000 rows, so this threshold is meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_counts = df.notna().sum().sort_values(ascending=False)\n",
    "keep_cols = non_null_counts[non_null_counts > 20000].index.tolist()\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns kept:\", len(keep_cols))\n",
    "non_null_counts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533cca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[keep_cols].copy()\n",
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156b96f",
   "metadata": {},
   "source": [
    "## Save cleaned dataframe\n",
    "\n",
    "We save the cleaned data to CSV for use in the analysis notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"AviationData_Cleaned.csv\"\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"Saved:\", OUTPUT_PATH)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
